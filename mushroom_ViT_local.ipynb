{"cells":[{"cell_type":"markdown","metadata":{},"source":["DOWNLOAD module"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4817,"status":"ok","timestamp":1698313373621,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"qFZhMkylUAFa","outputId":"85cd6fb1-df43-47b0-c6a9-e0d9265cbda0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (0.9.7)\n","Requirement already satisfied: matplotlib in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (3.8.0)\n","Requirement already satisfied: scikit-learn in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (1.3.2)\n","Requirement already satisfied: torch>=1.7 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from timm) (2.2.0.dev20231003+cu121)\n","Requirement already satisfied: torchvision in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from timm) (0.17.0.dev20231003+cu121)\n","Requirement already satisfied: pyyaml in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from timm) (0.17.3)\n","Requirement already satisfied: safetensors in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from timm) (0.3.3)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (1.24.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (9.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from matplotlib) (6.1.0)\n","Requirement already satisfied: scipy>=1.5.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: zipp>=3.1.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: filelock in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (3.9.0)\n","Requirement already satisfied: typing-extensions in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: sympy in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (3.0rc1)\n","Requirement already satisfied: jinja2 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: fsspec in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from torch>=1.7->timm) (2023.4.0)\n","Requirement already satisfied: requests in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->timm) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from requests->huggingface-hub->timm) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from requests->huggingface-hub->timm) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\syh\\anaconda3\\envs\\alpha\\lib\\site-packages (from sympy->torch>=1.7->timm) (1.2.1)\n"]}],"source":["!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install matplotlib scikit-learn timm tqdm"]},{"cell_type":"markdown","metadata":{},"source":["IMPORT MODULE"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698314259268,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"mXfbLGjWDKpr","outputId":"5805d474-d19a-44ce-b729-4d7f99011c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, random_split\n","from tqdm.notebook import tqdm\n","import timm\n","import torch.optim.lr_scheduler as lr_scheduler\n","import math\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, random_split\n","import pandas as pd\n","import numpy as np\n","import pickle\n","# Set the device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["PREPROCESS DATA"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":488,"status":"ok","timestamp":1698313464044,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"QsOKRQQ-DKpt"},"outputs":[],"source":["train_transform = transforms.Compose([\n","    # Geometric transformations\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(p=0.5),  # Flip the image with probability=0.5\n","    transforms.RandomVerticalFlip(p=0.5),  # Flip image vertically with probability=0.5\n","    transforms.RandomRotation(30),  # Rotate the image up to 30 degrees\n","    transforms.RandomRotation(60),  # Rotate the image up to 90 degrees\n","    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # Crop and resize\n","\n","    # Color transformations\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","\n","    # Affine transformations\n","    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n","\n","    # Convert to tensor\n","    transforms.ToTensor(),\n","\n","    # Cutout augmentation\n","    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n","\n","    # Normalize (Note: These values are standard for ImageNet. Adjust if using a different dataset)\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # This may be optional if your images are already this size\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for pretrained models on ImageNet\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["SET THE SEED VALUE FOR RANDOM SPLIT"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698313468261,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"1BLCauAhDKpu"},"outputs":[],"source":["def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\"\"\"\n","    torch.manual_seed(seed_value)  # Set the seed for torch\n","    torch.cuda.manual_seed(seed_value)  # If you're using GPU\n","    torch.cuda.manual_seed_all(seed_value)  # If using multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed_value)"]},{"cell_type":"markdown","metadata":{},"source":["LOAD DATA In Collab"]},{"cell_type":"markdown","metadata":{},"source":["LOAD DATA in local"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["local_path = './mushroom_data_new'"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1698314473699,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"StX6zUPnDKpu"},"outputs":[],"source":["set_seed(42)\n","\n","# 1. Load all data using ImageFolder\n","full_dataset = ImageFolder(root=local_path, transform=train_transform)\n","\n","# 2. Calculate lengths for train, validation, and test splits\n","total_size = len(full_dataset)\n","train_size = int(0.7 * total_size)  # 70% for training\n","val_size = int(0.2 * total_size)   # 20% for validation\n","test_size = total_size - train_size - val_size  # 10% for testing\n","\n","# 3. Use random_split to split the datasets\n","train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n","\n","# Optional: You might want to apply different transformations to validation and test sets (e.g., no augmentations).\n","# To do this, create a function that modifies the transformations for a given subset of the dataset:\n","def set_transform(dataset_subset, transform):\n","    dataset_subset.dataset.transform = transform\n","    return dataset_subset\n","\n","train_dataset = set_transform(train_dataset,train_transform)\n","val_dataset = set_transform(val_dataset, val_transform)  # If you have a separate val_transform without augmentations\n","test_dataset = set_transform(test_dataset, val_transform)  # Use the same as validation for simplicity\n","\n","\n","local_split_path = './split_data'\n","\n","\n","# Saving transformations\n","with open(local_split_path+'/train_dataset.pkl', 'wb') as f:\n","    pickle.dump(train_dataset, f)\n","with open(local_split_path+'/val_dataset.pkl', 'wb') as f:\n","    pickle.dump(val_dataset, f)\n","with open(local_split_path+'/test_dataset.pkl', 'wb') as f:\n","    pickle.dump(test_dataset, f)\n","\n","\n","# 4. Create DataLoaders for each set\n","trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"hXmum0EBDKpv"},"source":["1 PRETRAIN model 가져오기"]},{"cell_type":"markdown","metadata":{"id":"f4djddSvDKpw"},"source":["- vit_small_patch16_224: A smaller version of the ViT.\n","- vit_base_patch16_224: The standard-sized ViT.\n","- vit_large_patch16_224: A larger version of ViT.\n","- vit_huge_patch16_224: The biggest commonly available ViT.\n","\n","중에 선택 가능"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5539,"status":"ok","timestamp":1698314506376,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"MqsYbfqiDKpx","outputId":"4004062a-ddc5-4d2b-f8ae-4b3ebde0dc97"},"outputs":[{"name":"stdout","output_type":"stream","text":["model : vit_large_patch16_224\n","class num : 215\n"]}],"source":["model_name = \"vit_large_patch16_224\"\n","\n","model = timm.create_model(model_name, pretrained=True)\n","\n","# Adjust the head of the model for your specific number of classes (e.g., number of mushroom types)\n","num_classes = len(full_dataset.classes)\n","model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=num_classes)\n","\n","print(f'model : {model_name}')\n","print(f'class num : {num_classes}')"]},{"cell_type":"markdown","metadata":{"id":"aPbol9hmDKpx"},"source":["2 이미 학습된 버섯 모델 파라미터 가져오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdlGyENsDKpx"},"outputs":[],"source":["# Assuming 'model' is the instance of your model\n","# model.load_state_dict(torch.load('./model_save/mushroom_vit_large_patch16_224.pth'))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6048,"status":"ok","timestamp":1698314527673,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"dPqIqhcsDKpx"},"outputs":[],"source":["# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define a loss function and an optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":492,"referenced_widgets":["461729beb51b42f7a25f395d8e3747f0","fa067b6dc8894286bba54509320b52c3","2f799f7e772a480984acaa63ed668410","cd71378734124f8eba217952315e8914","cb73135f530342e1a60be9eb6b525a97","1e0dc05362eb426da2926bf792d64c2d","73181b7d16ee4a61b4733f27327c6603","361d3e6d4ba245ac839541a4874b7941","b2bed6be5f1a4a92938b7aa3486d0007","1d77baabe4c1470c9f4c48f93996d49e","497ed907b92d49748a300db51642c071"]},"executionInfo":{"elapsed":64901,"status":"error","timestamp":1698314603459,"user":{"displayName":"정새벽","userId":"13631030780005210157"},"user_tz":-540},"id":"zCu1iQkVDKpy","outputId":"5ff1ddcf-cc49-4f29-d3c0-a710e712560c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58001d12361949cd984954b1b0fd1ef4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/279 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\SYH\\anaconda3\\envs\\alpha\\lib\\site-packages\\timm\\models\\vision_transformer.py:86: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:235.)\n","  x = F.scaled_dot_product_attention(\n"]},{"name":"stdout","output_type":"stream","text":["[1, 10] loss: 6.31600, accuracy: 2.19%\n","[1, 20] loss: 5.45661, accuracy: 4.69%\n","[1, 30] loss: 4.76632, accuracy: 11.56%\n","[1, 40] loss: 4.24723, accuracy: 17.50%\n","[1, 50] loss: 3.77502, accuracy: 19.38%\n","[1, 60] loss: 3.21420, accuracy: 30.94%\n","[1, 70] loss: 3.05459, accuracy: 30.62%\n","[1, 80] loss: 2.68063, accuracy: 34.06%\n","[1, 90] loss: 2.42023, accuracy: 39.38%\n","[1, 100] loss: 2.35494, accuracy: 40.94%\n","[1, 110] loss: 2.33039, accuracy: 43.75%\n","[1, 120] loss: 2.30040, accuracy: 45.00%\n"]}],"source":["# Assuming you have set the device as 'cuda' if available, otherwise 'cpu'\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hyperparameters\n","num_epochs = 3\n","print_every = 10  # Adjust this value to control how often you want to print updates\n","\n","# Send the model to the device\n","model = model.to(device)\n","\n","# Training Loop\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode\n","\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    # Training loopW\n","    for i, (inputs, labels) in tqdm(enumerate(trainloader), total=len(trainloader)):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","        if i % print_every == (print_every - 1):  # Print every 'print_every' batches\n","            interval_accuracy = 100 * correct_train / (print_every * trainloader.batch_size)\n","            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / print_every:.5f}, accuracy: {interval_accuracy:.2f}%\")\n","            running_loss = 0.0\n","            correct_train = 0  # Reset for the next set of batches\n","\n","\n","    # train_accuracy = 100 * correct_train / total_train\n","    # print(f\"Epoch {epoch + 1}/{num_epochs}, Training accuracy: {train_accuracy:.2f}%\")\n","\n","    # Validation loop\n","    model.eval()  # Set the model to evaluation mode\n","    correct_val = 0\n","    total_val = 0\n","    val_loss = 0.0\n","    with torch.no_grad():  # No gradient needed for validation\n","        for images, labels in valloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","            val_loss += loss.item()\n","\n","    val_accuracy = 100 * correct_val / total_val\n","    average_val_loss = val_loss / len(valloader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss:.5f}, Validation accuracy: {val_accuracy:.2f}%\")\n","\n","print(\"Finished Training!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXgLr4r7DKpy"},"outputs":[],"source":["# Saving the model's state_dict\n","torch.save(model.state_dict(), './model_save/mushroom_vit_large_patch16_224_4.pth')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1d77baabe4c1470c9f4c48f93996d49e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0dc05362eb426da2926bf792d64c2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f799f7e772a480984acaa63ed668410":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_361d3e6d4ba245ac839541a4874b7941","max":279,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2bed6be5f1a4a92938b7aa3486d0007","value":1}},"361d3e6d4ba245ac839541a4874b7941":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"461729beb51b42f7a25f395d8e3747f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa067b6dc8894286bba54509320b52c3","IPY_MODEL_2f799f7e772a480984acaa63ed668410","IPY_MODEL_cd71378734124f8eba217952315e8914"],"layout":"IPY_MODEL_cb73135f530342e1a60be9eb6b525a97"}},"497ed907b92d49748a300db51642c071":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73181b7d16ee4a61b4733f27327c6603":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2bed6be5f1a4a92938b7aa3486d0007":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb73135f530342e1a60be9eb6b525a97":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd71378734124f8eba217952315e8914":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d77baabe4c1470c9f4c48f93996d49e","placeholder":"​","style":"IPY_MODEL_497ed907b92d49748a300db51642c071","value":" 1/279 [01:04&lt;2:47:24, 36.13s/it]"}},"fa067b6dc8894286bba54509320b52c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0dc05362eb426da2926bf792d64c2d","placeholder":"​","style":"IPY_MODEL_73181b7d16ee4a61b4733f27327c6603","value":"  0%"}}}}},"nbformat":4,"nbformat_minor":0}
